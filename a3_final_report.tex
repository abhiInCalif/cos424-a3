\documentclass{article} % For LaTeX2e
\usepackage{cos424,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{float}
\usepackage{graphicx}


\title{Link Prediction in Sparse Bitcoin Transaction Network}


\author{
Abhinav Khanna\\
Student Researcher\\
\texttt{akhanna@princeton.edu} \\
\And
 \\
Student Researcher \\
\texttt{example@princeton.edu} \\
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

\section{Related Work}
There are many lenses with which we chose to approach the problem. If we treat this problem like a recommendation problem of recommending one user to another, than we base our knowledge off of the field of recommendation engines. Collaborative Filtering is one of the most successful recommendation system techniques (Su 2009). However, traditionally, collaborative filtering has problems dealing with scale and sparsity. The previously cited paper reference hybrid models as a way to combat sparsity and scale. The Netflix recommendation challenge is an area where collaborative filtering has often been used to produce good results. Paterak in his paper, "Improving regularized singular value decomposition for collaborative filtering," cites an SVD to KMeans to KNN collaborative filtering pipeline that works well on the Netflix challenge dataset. In addition to model based techniques for dealing with sparsity for collaborative filtering, a process known as transfer learning can also be used to take a similar dense data set and utilize that to augment the sparse data set (Pan, Xiang, Liu).

Under the lens of predicting future interactions of a social network, Vinti Agarwal's paper provides a friend recommendation system -- a very analogous problem -- that relies on collaborative filtering and utilizes adaptive similarity and missing data prediction algorithms to improve upon the sparsity issue (Agarwal, Bharadwaj). Some general link prediction mechanisms are presented in a paper by Kleinberg and Liben-Nowell, and many of those techniques have been replicated here (Liben-Nowell, Kleinberg).

\section{Methods}
\subsection{Description of data}
\subsection{Imputation Pipelines}
\subsection{Evaluation}
\section{Results}
\section{Discussion and Conclusion}
\subsubsection*{Acknowledgments}
We would like to acknowledge Princeton University for offering the wonderful COS 424 class that provided us with the opportunity to take on this research. We would also like to thank our Professor, Professor Englehart, and her TA team for providing us with guidance and the tools necessary to make this project happen.

\bibliography{References}
\subsubsection*{References}
[1] - Weiwei Zhang, Tim D Spector, Panos Deloukas, Jordana T Bell, and Barbara E Engelhardt. Predicting genome-wide dna methylation using methylation marks, genomic position, and dna regulatory elements. arXiv preprint arXiv:1308.2134, 2013
\newline
\newline
[2] - Peter W Laird. Principles and challenges of genomewide DNA methylation analysis. Nature reviews. Genetics, 11(3):191â€“203, March 2010. ISSN 1471-0064. doi: 10.1038/nrg2732. URL http://www.ncbi.nlm.nih.gov/pubmed/20125086.
\newline
\newline
[3] - Next-Generation Sequencing (NGS). (n.d.). Retrieved March 22, 2016, from http://www.illumina.com/technology/next-generation-sequencing.html
\newline
\newline
[4] - Bjo/methylation\_imputation. (n.d.). Retrieved March 22, 2016, from https://github.com/bjo/methylation\_imputation

\end{document}
